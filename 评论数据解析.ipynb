{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 数据导入"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': {'$oid': '65b08e2adc0113065d559971'}, 'o_tid': '1502290921521618952', 'cid': '1574597356313616389', 'seq': 1, 'retweet_num': 2, 'quote_num': 0, 'comment_num': 1, 'like_num': 3, 'view_num': 0, 'created_t': {'$date': '2022-09-27T03:10:39.000Z'}, 'ts': {'$date': '2024-01-24T04:12:26.364Z'}, 'comment_user': {'uid': '1390526374893457408', 'screen_name': 'Pastie1999', 'nick_name': 'King Saifalaah', 'created_t': {'$date': '2021-05-07T04:38:51.000Z'}, 'brief_introduction': 'Second King of the UK 🇬🇧 Martyn Son of Martin grandson of Martin. The Pastie King, i.e., King Saifalaah 👽\\n\\nSaifalaah27-Ytube \\nAskTheAudience-Deso', 'pos': 'England, United Kingdom', 'follow_num': 99, 'fan_num': 192, 'post_num': 2775}}, {'_id': {'$oid': '65b08e2adc0113065d559975'}, 'o_tid': '1501962856555757577', 'cid': '1502291189868998661', 'seq': 1, 'retweet_num': 0, 'quote_num': 0, 'comment_num': 0, 'like_num': 0, 'view_num': 0, 'created_t': {'$date': '2022-03-11T14:31:45.000Z'}, 'ts': {'$date': '2024-01-24T04:12:26.477Z'}, 'comment_user': {'uid': '235717819', 'screen_name': 'KNugent4118', 'nick_name': 'KNugent4118 🇨🇦🇨🇦🇨🇦', 'created_t': {'$date': '2011-01-08T22:50:53.000Z'}, 'brief_introduction': \"I am a proud Canadian  Liberal because I believe in progress and democracy. \\nToday's Conservatives aren't worth the risk. \\n#Woke \\n#CeasefireNow\\n#SlavaUkraini\", 'pos': 'Ontario, Canada', 'follow_num': 6919, 'fan_num': 11308, 'post_num': 56336}}, {'_id': {'$oid': '65b08e2bdc0113065d55997a'}, 'o_tid': '1501962856555757577', 'cid': '1501964633946656769', 'seq': 2, 'retweet_num': 0, 'quote_num': 0, 'comment_num': 0, 'like_num': 0, 'view_num': 0, 'created_t': {'$date': '2022-03-10T16:54:08.000Z'}, 'ts': {'$date': '2024-01-24T04:12:26.477Z'}, 'comment_user': {'uid': '168854269', 'screen_name': 'Stuwba68', 'nick_name': 'StuWba68', 'created_t': {'$date': '2010-07-20T23:30:37.000Z'}, 'brief_introduction': 'Baggies fan with a limited life 😞', 'pos': '', 'follow_num': 354, 'fan_num': 741, 'post_num': 49770}}, {'_id': {'$oid': '65b08e2adc0113065d559978'}, 'o_tid': '1503808533523009542', 'cid': '1729132699095294081', 'seq': 1, 'retweet_num': 1, 'quote_num': 0, 'comment_num': 12, 'like_num': 8, 'view_num': 3339, 'created_t': {'$date': '2023-11-27T13:38:55.000Z'}, 'ts': {'$date': '2024-01-24T04:12:26.586Z'}, 'comment_user': {'uid': '1702225799426752513', 'screen_name': 'Casper549950684', 'nick_name': '“ThoughtFusionHub”', 'created_t': {'$date': '2023-09-14T07:41:01.000Z'}, 'brief_introduction': '“Where philosophy, politics, and creative chaos collide! 🧠🗳️🎨 Let’s think, laugh, and change the world, one tweet at a time. 😄 Followers are  welcome.', 'pos': 'Almelo, Nederland', 'follow_num': 579, 'fan_num': 279, 'post_num': 462}}, {'_id': {'$oid': '65b08e2adc0113065d559973'}, 'o_tid': '1499784539698348036', 'cid': '1500170439720517635', 'seq': 1, 'retweet_num': 1, 'quote_num': 0, 'comment_num': 48, 'like_num': 15, 'view_num': 0, 'created_t': {'$date': '2022-03-05T18:04:39.000Z'}, 'ts': {'$date': '2024-01-24T04:12:26.430Z'}, 'comment_user': {'uid': '1370894774505500673', 'screen_name': 'AgenorFritz', 'nick_name': 'Fritz Kim', 'created_t': {'$date': '2021-03-14T00:31:48.000Z'}, 'brief_introduction': '', 'pos': '', 'follow_num': 132, 'fan_num': 24, 'post_num': 1484}}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "datas = []\n",
    "# 打开JSON文件\n",
    "with open('data\\\\TweetReviews_new.json', 'r', encoding='utf-8') as file:\n",
    "    datas = json.load(file)\n",
    "\n",
    "print(datas[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 关键数据提取"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-27T03:10:39.000Z\n",
      "2022-09-27 03:10:39\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "def getDate(t_str):\n",
    "    t_str = t_str.split('.')[0]\n",
    "    d = datetime.datetime.strptime(t_str, '%Y-%m-%dT%H:%M:%S')\n",
    "    return d\n",
    "ct = datas[0]['created_t']['$date']\n",
    "print(ct)\n",
    "d = getDate(ct)\n",
    "print(d)\n",
    "\n",
    "o_tids = [] # 原推文id\n",
    "seqs = [] # 排序\n",
    "like_nums = [] # 点赞\n",
    "retweet_nums = [] # 快转\n",
    "quote_nums = [] # 转发\n",
    "comment_nums = [] # 评论\n",
    "view_nums = [] # 浏览数\n",
    "follow_nums = [] # 关注\n",
    "fan_nums = [] # 粉丝\n",
    "post_nums = [] # 发推数\n",
    "created_ts = [] # 创建时间\n",
    "\n",
    "for data in datas:\n",
    "    o_tids.append(data['o_tid'])\n",
    "    seqs.append(data['seq'])\n",
    "    like_nums.append(data['like_num'])\n",
    "    retweet_nums.append(data['retweet_num'])\n",
    "    quote_nums.append(data['quote_num'])\n",
    "    comment_nums.append(data['comment_num'])\n",
    "    view_nums.append(data['view_num'])\n",
    "    follow_nums.append(data['comment_user']['follow_num'])\n",
    "    fan_nums.append(data['comment_user']['fan_num'])\n",
    "    post_nums.append(data['comment_user']['post_num'])\n",
    "    created_ts.append(getDate(data['created_t']['$date']).timestamp())\n",
    "\n",
    "# df = pd.DataFrame(data=[seqs, like_nums, retweet_nums, quote_nums, comment_nums, view_nums, follow_nums, fan_nums, post_nums, created_ts], columns=['seq', 'like_num', 'retweet_num', 'quote_num', 'comment_num', 'view_num', 'follow_num', 'fan_num', 'post_num', 'date'])\n",
    "df = pd.DataFrame(data={\n",
    "    'o_tid': o_tids,\n",
    "    'seq': seqs,\n",
    "    'like_num': like_nums,\n",
    "    'retweet_num': retweet_nums,\n",
    "    'quote_num': quote_nums,\n",
    "    'comment_num': comment_nums,\n",
    "    'view_num': view_nums,\n",
    "    'follow_num': follow_nums,\n",
    "    'fan_num': fan_nums,\n",
    "    'post_num': post_nums,\n",
    "    'date': created_ts\n",
    "})\n",
    "df.sort_values(['o_tid', 'seq'], inplace=True)\n",
    "df.head(100)\n",
    "df.to_csv('data/res.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "group = df.groupby(df.o_tid)\n",
    "for g in group:\n",
    "    # print(type(g[0])) # 0是组号，1是数据\n",
    "    # print(g[0])\n",
    "    g[1].to_csv(f'data/tweet_id/{g[0]}.csv', index=False)\n",
    "    # break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 模型定义"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(in_features=9, out_features=32, dtype=float),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=32, out_features=1, dtype=float)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 数据集定义"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class MyDataSet(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.x = df.drop(labels=['seq'], axis=1)\n",
    "        self.x = torch.from_numpy(self.x.values)\n",
    "        self.x = self.x.double()\n",
    "        self.y = torch.from_numpy(df['seq'].values)\n",
    "        self.y = self.y.double()\n",
    "        # print(self.x.size())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        x = self.x[item]\n",
    "        y = self.y[item]\n",
    "        return x, y\n",
    "\n",
    "class PairWiseDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df.drop(labels=['seq'], axis=1)\n",
    "        self.df = torch.from_numpy(self.df.values)\n",
    "        self.index = []\n",
    "        n = self.df.shape[0]\n",
    "        print(self.df.shape)\n",
    "        print(n)\n",
    "        for i in range(n):\n",
    "            for j in range(i+1, n):\n",
    "                self.index.append([i, j])\n",
    "\n",
    "        self.y = torch.from_numpy(df['seq'].values)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.index)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        i = self.index[item]\n",
    "        x1 = self.df[i[0]]\n",
    "        x2 = self.df[i[1]]\n",
    "        y1 = self.y[i[0]]\n",
    "        y2 = self.y[i[1]]\n",
    "        return x1, x2, y1, y2\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 准备数据集"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# # 超参数\n",
    "# lr = 1e-8\n",
    "# epochs = 300\n",
    "# batch_size = 16\n",
    "# train_rate = 0.8\n",
    "# train_len = int(train_rate * len(df))\n",
    "#\n",
    "# df = pd.read_csv('data/res.csv')\n",
    "# train_ds = MyDataSet(df[:train_len])\n",
    "# trainLoader = DataLoader(train_ds, shuffle=True, batch_size=batch_size)\n",
    "# test_ds = MyDataSet(df[train_len:])\n",
    "# testLoader = DataLoader(test_ds, shuffle=True, batch_size=1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "# def train_model(model):\n",
    "#     loss_list = []\n",
    "#\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "#     criterion = nn.MSELoss(reduction='mean')\n",
    "#     model.train()\n",
    "#     for epoch in range(epochs):\n",
    "#         tot_loss = 0.0\n",
    "#         batch_num = 0\n",
    "#         for i, (x, y) in enumerate(trainLoader):\n",
    "#             batch_num += 1\n",
    "#             optimizer.zero_grad()\n",
    "#             pred_y = model(x)\n",
    "#\n",
    "#             loss = criterion(pred_y, y)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             # print(loss)\n",
    "#             # print(y.size(0))\n",
    "#             tot_loss += loss.item() / y.size(0)\n",
    "#\n",
    "#         print(f'epoch = {epoch}  loss = {tot_loss / batch_num}')\n",
    "#         loss_list.append(tot_loss / batch_num)\n",
    "#\n",
    "#     loss_df = pd.DataFrame(data=loss_list, columns=['loss'])\n",
    "#     loss_df.to_csv('loss.csv', index=False)\n",
    "#\n",
    "# model = MyModel()\n",
    "# train_model(model)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0  loss = 0.039777707860988824\n",
      "epoch = 1  loss = 0.03595682270376549\n",
      "epoch = 2  loss = 0.19388461785009867\n",
      "epoch = 3  loss = 0.037724785868922556\n",
      "epoch = 4  loss = 0.03647122701687503\n",
      "epoch = 5  loss = 0.33824767368913383\n",
      "epoch = 6  loss = 0.03437943354810426\n",
      "epoch = 7  loss = 0.0472337856744516\n",
      "epoch = 8  loss = 0.03507786830258519\n",
      "epoch = 9  loss = 0.083509106964871\n",
      "epoch = 10  loss = 0.036786019853557485\n",
      "epoch = 11  loss = 0.048675060750208\n",
      "epoch = 12  loss = 0.03596132951903131\n",
      "epoch = 13  loss = 0.06806215870870089\n",
      "epoch = 14  loss = 0.03713265269183788\n",
      "epoch = 15  loss = 0.07741613195422493\n",
      "epoch = 16  loss = 0.0363564938825347\n",
      "epoch = 17  loss = 0.052442323913566735\n",
      "epoch = 18  loss = 0.03471307193208339\n",
      "epoch = 19  loss = 0.08611982412429645\n",
      "epoch = 20  loss = 0.03482061955650897\n",
      "epoch = 21  loss = 0.06467269602431981\n",
      "epoch = 22  loss = 0.03699148698339033\n",
      "epoch = 23  loss = 0.06063010275855169\n",
      "epoch = 24  loss = 0.036311151724735646\n",
      "epoch = 25  loss = 0.035561942932557086\n",
      "epoch = 26  loss = 0.0374859857713596\n",
      "epoch = 27  loss = 0.15799203969183423\n",
      "epoch = 28  loss = 0.036117798927440374\n",
      "epoch = 29  loss = 0.03644674205611602\n",
      "epoch = 30  loss = 0.033427735604443266\n",
      "epoch = 31  loss = 0.17321021565002712\n",
      "epoch = 32  loss = 0.03710452453596376\n",
      "epoch = 33  loss = 0.04350178194866325\n",
      "epoch = 34  loss = 0.03387408757992654\n",
      "epoch = 35  loss = 0.07958850737550008\n",
      "epoch = 36  loss = 0.03710319078612676\n",
      "epoch = 37  loss = 0.04880928470202917\n",
      "epoch = 38  loss = 0.036128996015140864\n",
      "epoch = 39  loss = 0.1383388848364166\n",
      "epoch = 40  loss = 0.03584421006704362\n",
      "epoch = 41  loss = 0.05280724285177259\n",
      "epoch = 42  loss = 0.032883826707948385\n",
      "epoch = 43  loss = 0.07963510741860313\n",
      "epoch = 44  loss = 0.037472831413407175\n",
      "epoch = 45  loss = 0.0464535058644166\n",
      "epoch = 46  loss = 0.034170879257140144\n",
      "epoch = 47  loss = 0.05384620043392084\n",
      "epoch = 48  loss = 0.03690116354023081\n",
      "epoch = 49  loss = 0.07189845876823789\n",
      "epoch = 50  loss = 0.03844362464969786\n",
      "epoch = 51  loss = 0.060103456321606644\n",
      "epoch = 52  loss = 0.03481801489981165\n",
      "epoch = 53  loss = 0.03754406567489458\n",
      "epoch = 54  loss = 0.0356486828230645\n",
      "epoch = 55  loss = 0.12166474319171806\n",
      "epoch = 56  loss = 0.03740503890493476\n",
      "epoch = 57  loss = 0.04195328135489794\n",
      "epoch = 58  loss = 0.03500355128130633\n",
      "epoch = 59  loss = 0.0987802290022841\n",
      "epoch = 60  loss = 0.03631623519310647\n",
      "epoch = 61  loss = 0.04294671264697843\n",
      "epoch = 62  loss = 0.03701995864222026\n",
      "epoch = 63  loss = 0.0714553448595282\n",
      "epoch = 64  loss = 0.03725904530564383\n",
      "epoch = 65  loss = 0.051939005372740724\n",
      "epoch = 66  loss = 0.03396768235547389\n",
      "epoch = 67  loss = 0.09148072028763628\n",
      "epoch = 68  loss = 0.033457429405674144\n",
      "epoch = 69  loss = 0.0868244747445572\n",
      "epoch = 70  loss = 0.03866042015729994\n",
      "epoch = 71  loss = 0.048261275333471784\n",
      "epoch = 72  loss = 0.03795095598047345\n",
      "epoch = 73  loss = 0.055481801729031346\n",
      "epoch = 74  loss = 0.034600165396273794\n",
      "epoch = 75  loss = 0.11283884460173746\n",
      "epoch = 76  loss = 0.035595598791529535\n",
      "epoch = 77  loss = 0.06390955998425331\n",
      "epoch = 78  loss = 0.03616441776308322\n",
      "epoch = 79  loss = 0.0650783023929047\n",
      "epoch = 80  loss = 0.03824384988820223\n",
      "epoch = 81  loss = 0.07504316627909101\n",
      "epoch = 82  loss = 0.036090053043663035\n",
      "epoch = 83  loss = 0.0480231544602329\n",
      "epoch = 84  loss = 0.035858318739103334\n",
      "epoch = 85  loss = 0.081021031353687\n",
      "epoch = 86  loss = 0.03503389564844278\n",
      "epoch = 87  loss = 0.06029561486256989\n",
      "epoch = 88  loss = 0.03399580777595955\n",
      "epoch = 89  loss = 0.03813726250208965\n",
      "epoch = 90  loss = 0.03602531930808931\n",
      "epoch = 91  loss = 0.0933601893948548\n",
      "epoch = 92  loss = 0.03561905578348039\n",
      "epoch = 93  loss = 0.03492016468971016\n",
      "epoch = 94  loss = 0.24291955891086256\n",
      "epoch = 95  loss = 0.0367706799385499\n",
      "epoch = 96  loss = 0.03579719759551162\n",
      "epoch = 97  loss = 0.21906730776827166\n",
      "epoch = 98  loss = 0.03858189828058364\n",
      "epoch = 99  loss = 0.0396125573959262\n",
      "epoch = 100  loss = 0.03728768784554762\n",
      "epoch = 101  loss = 0.1197887245115343\n",
      "epoch = 102  loss = 0.03530574200829868\n",
      "epoch = 103  loss = 0.036719448190749716\n",
      "epoch = 104  loss = 0.3171271535955381\n",
      "epoch = 105  loss = 0.03842353662393094\n",
      "epoch = 106  loss = 0.047888803708965026\n",
      "epoch = 107  loss = 0.03589202009613198\n",
      "epoch = 108  loss = 0.07594597271596307\n",
      "epoch = 109  loss = 0.03587732489573153\n",
      "epoch = 110  loss = 0.035313537580018144\n",
      "epoch = 111  loss = 0.03562181718152334\n",
      "epoch = 112  loss = 0.19426428681538718\n",
      "epoch = 113  loss = 0.03691260674661333\n",
      "epoch = 114  loss = 0.03439492742111394\n",
      "epoch = 115  loss = 0.29393294792269486\n",
      "epoch = 116  loss = 0.03847151967452684\n",
      "epoch = 117  loss = 0.03808396743081241\n",
      "epoch = 118  loss = 0.03470342527160714\n",
      "epoch = 119  loss = 0.1711801054261231\n",
      "epoch = 120  loss = 0.03600878569583566\n",
      "epoch = 121  loss = 0.035001096876035\n",
      "epoch = 122  loss = 0.03592476505944081\n",
      "epoch = 123  loss = 0.1443647299825459\n",
      "epoch = 124  loss = 0.035465135421040545\n",
      "epoch = 125  loss = 0.049179219166796476\n",
      "epoch = 126  loss = 0.036642982786953104\n",
      "epoch = 127  loss = 0.06289225708379413\n",
      "epoch = 128  loss = 0.0368131172319378\n",
      "epoch = 129  loss = 0.043460266061287035\n",
      "epoch = 130  loss = 0.035389170109492704\n",
      "epoch = 131  loss = 0.09006131016252117\n",
      "epoch = 132  loss = 0.03401023185398178\n",
      "epoch = 133  loss = 0.0558370456321741\n",
      "epoch = 134  loss = 0.03787873992818241\n",
      "epoch = 135  loss = 0.04984526603065006\n",
      "epoch = 136  loss = 0.03407875932967519\n",
      "epoch = 137  loss = 0.13651149945771238\n",
      "epoch = 138  loss = 0.03675822493318548\n",
      "epoch = 139  loss = 0.053095596931262645\n",
      "epoch = 140  loss = 0.0332928223639711\n",
      "epoch = 141  loss = 0.11516174207193448\n",
      "epoch = 142  loss = 0.038426126837964335\n",
      "epoch = 143  loss = 0.04213983423107273\n",
      "epoch = 144  loss = 0.03705041495871631\n",
      "epoch = 145  loss = 0.09224002780962964\n",
      "epoch = 146  loss = 0.03479713557482015\n",
      "epoch = 147  loss = 0.044624509008563296\n",
      "epoch = 148  loss = 0.036627481876634164\n",
      "epoch = 149  loss = 0.09591109892309554\n",
      "epoch = 150  loss = 0.03764426467432394\n",
      "epoch = 151  loss = 0.05325960931487573\n",
      "epoch = 152  loss = 0.035789214201322216\n",
      "epoch = 153  loss = 0.07451498268210158\n",
      "epoch = 154  loss = 0.03773235904919359\n",
      "epoch = 155  loss = 0.06904775366179298\n",
      "epoch = 156  loss = 0.03714965613708017\n",
      "epoch = 157  loss = 0.07806901743724233\n",
      "epoch = 158  loss = 0.03493974940828913\n",
      "epoch = 159  loss = 0.06656909251730833\n",
      "epoch = 160  loss = 0.03619831801708427\n",
      "epoch = 161  loss = 0.07392809942037194\n",
      "epoch = 162  loss = 0.03581370063270342\n",
      "epoch = 163  loss = 0.05555948599907879\n",
      "epoch = 164  loss = 0.036223877256824855\n",
      "epoch = 165  loss = 0.05112475638752019\n",
      "epoch = 166  loss = 0.037503626787462885\n",
      "epoch = 167  loss = 0.07957409285535244\n",
      "epoch = 168  loss = 0.03538392133765168\n",
      "epoch = 169  loss = 0.04629099000808708\n",
      "epoch = 170  loss = 0.03815009354656121\n",
      "epoch = 171  loss = 0.054787956476055596\n",
      "epoch = 172  loss = 0.03840145248352452\n",
      "epoch = 173  loss = 0.09655331144277991\n",
      "epoch = 174  loss = 0.037585879448647275\n",
      "epoch = 175  loss = 0.056102212237740985\n",
      "epoch = 176  loss = 0.03670205816720119\n",
      "epoch = 177  loss = 0.08909047291829036\n",
      "epoch = 178  loss = 0.03728515173263228\n",
      "epoch = 179  loss = 0.06545216882029234\n",
      "epoch = 180  loss = 0.03433099353207399\n",
      "epoch = 181  loss = 0.055707167525649505\n",
      "epoch = 182  loss = 0.03780907574146284\n",
      "epoch = 183  loss = 0.04390805628772558\n",
      "epoch = 184  loss = 0.03517232459098927\n",
      "epoch = 185  loss = 0.06083929528122108\n",
      "epoch = 186  loss = 0.034840691098207484\n",
      "epoch = 187  loss = 0.07124532791120665\n",
      "epoch = 188  loss = 0.037975175132120176\n",
      "epoch = 189  loss = 0.05386651645837062\n",
      "epoch = 190  loss = 0.03748457159034124\n",
      "epoch = 191  loss = 0.03572496984842122\n",
      "epoch = 192  loss = 0.03629316343788949\n",
      "epoch = 193  loss = 0.15037000641296946\n",
      "epoch = 194  loss = 0.03513282615358077\n",
      "epoch = 195  loss = 0.06085850487768745\n",
      "epoch = 196  loss = 0.03607501194840136\n",
      "epoch = 197  loss = 0.06733737448196271\n",
      "epoch = 198  loss = 0.03437315472043478\n",
      "epoch = 199  loss = 0.062267784101372944\n",
      "epoch = 200  loss = 0.034785729764426086\n",
      "epoch = 201  loss = 0.059293192494046555\n",
      "epoch = 202  loss = 0.033976686421892895\n",
      "epoch = 203  loss = 0.06480229616180756\n",
      "epoch = 204  loss = 0.03715138451660696\n",
      "epoch = 205  loss = 0.06666765599226465\n",
      "epoch = 206  loss = 0.03547516434932491\n",
      "epoch = 207  loss = 0.07935051727145208\n",
      "epoch = 208  loss = 0.03772454249849499\n",
      "epoch = 209  loss = 0.06566136190945537\n",
      "epoch = 210  loss = 0.033020486336831086\n",
      "epoch = 211  loss = 0.0650756079865369\n",
      "epoch = 212  loss = 0.034124849596724086\n",
      "epoch = 213  loss = 0.06260168441595175\n",
      "epoch = 214  loss = 0.035034038862559506\n",
      "epoch = 215  loss = 0.057955434036498166\n",
      "epoch = 216  loss = 0.03612773666584261\n",
      "epoch = 217  loss = 0.06292272986018614\n",
      "epoch = 218  loss = 0.03608575519047627\n",
      "epoch = 219  loss = 0.06052724209905045\n",
      "epoch = 220  loss = 0.03857492748618687\n",
      "epoch = 221  loss = 0.13321280936368907\n",
      "epoch = 222  loss = 0.037919604251953655\n",
      "epoch = 223  loss = 0.04015234353957471\n",
      "epoch = 224  loss = 0.03445631982432118\n",
      "epoch = 225  loss = 0.11161365500416885\n",
      "epoch = 226  loss = 0.03717877060518035\n",
      "epoch = 227  loss = 0.05926739847329448\n",
      "epoch = 228  loss = 0.03615682392509304\n",
      "epoch = 229  loss = 0.07302226969813377\n",
      "epoch = 230  loss = 0.03487494102265434\n",
      "epoch = 231  loss = 0.04881963579404237\n",
      "epoch = 232  loss = 0.03552132386271708\n",
      "epoch = 233  loss = 0.06406429810737016\n",
      "epoch = 234  loss = 0.034677458599732244\n",
      "epoch = 235  loss = 0.08270815018075164\n",
      "epoch = 236  loss = 0.03684951269785688\n",
      "epoch = 237  loss = 0.04559809329784521\n",
      "epoch = 238  loss = 0.03428731442261965\n",
      "epoch = 239  loss = 0.08119353587046647\n",
      "epoch = 240  loss = 0.036629618876255474\n",
      "epoch = 241  loss = 0.06464739582890743\n",
      "epoch = 242  loss = 0.03718280302626746\n",
      "epoch = 243  loss = 0.07309534715957382\n",
      "epoch = 244  loss = 0.03383237462488848\n",
      "epoch = 245  loss = 0.03716320948629464\n",
      "epoch = 246  loss = 0.037652364509274734\n",
      "epoch = 247  loss = 0.09152788764235238\n",
      "epoch = 248  loss = 0.034534202674759554\n",
      "epoch = 249  loss = 0.050440509787705604\n",
      "epoch = 250  loss = 0.035475873928039504\n",
      "epoch = 251  loss = 0.07607625147931119\n",
      "epoch = 252  loss = 0.036424382212647335\n",
      "epoch = 253  loss = 0.034517125473447895\n",
      "epoch = 254  loss = 0.03639167405622034\n",
      "epoch = 255  loss = 0.11289480422754553\n",
      "epoch = 256  loss = 0.03552379979786608\n",
      "epoch = 257  loss = 0.05192083778656134\n",
      "epoch = 258  loss = 0.03360542032861822\n",
      "epoch = 259  loss = 0.07000243765702116\n",
      "epoch = 260  loss = 0.0346227842177913\n",
      "epoch = 261  loss = 0.06124245984307264\n",
      "epoch = 262  loss = 0.035100300561720504\n",
      "epoch = 263  loss = 0.059335423386857995\n",
      "epoch = 264  loss = 0.03283139790253824\n",
      "epoch = 265  loss = 0.045401797892378616\n",
      "epoch = 266  loss = 0.03543144385815293\n",
      "epoch = 267  loss = 0.08293511615076782\n",
      "epoch = 268  loss = 0.036977032855862665\n",
      "epoch = 269  loss = 0.057285641279599855\n",
      "epoch = 270  loss = 0.03793577891932864\n",
      "epoch = 273  loss = 0.05253802503530796\n",
      "epoch = 274  loss = 0.035744605102288295\n",
      "epoch = 271  loss = 0.0582627790673499\n",
      "epoch = 272  loss = 0.03750436156793205\n",
      "epoch = 275  loss = 0.1129065051546183\n",
      "epoch = 276  loss = 0.03778321834632952\n",
      "epoch = 277  loss = 0.05740623642977528\n",
      "epoch = 281  loss = 0.05619934159367575\n",
      "epoch = 282  loss = 0.03610253189049548\n",
      "epoch = 278  loss = 0.03767861082588485\n",
      "epoch = 279  loss = 0.08961791854131478\n",
      "epoch = 280  loss = 0.036987723228835985\n",
      "epoch = 283  loss = 0.09132035553517734\n",
      "epoch = 284  loss = 0.037847629924412485\n",
      "epoch = 285  loss = 0.04704169338400423\n",
      "epoch = 286  loss = 0.0360326350355167\n",
      "epoch = 287  loss = 0.10225102814710746\n",
      "epoch = 288  loss = 0.03814094181673056\n",
      "epoch = 289  loss = 0.04388902636916462\n",
      "epoch = 290  loss = 0.03694028922715841\n",
      "epoch = 291  loss = 0.07065301346434216\n",
      "epoch = 292  loss = 0.03505823216330375\n",
      "epoch = 293  loss = 0.09037686258414103\n",
      "epoch = 294  loss = 0.03642466987562643\n",
      "epoch = 295  loss = 0.07001897647025572\n",
      "epoch = 296  loss = 0.03602729744230622\n",
      "epoch = 297  loss = 0.06256997885347224\n",
      "epoch = 298  loss = 0.03736720130486928\n",
      "epoch = 299  loss = 0.07943500224276714\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# df = pd.read_csv('data/tweet_id/474188805541748736.csv')\n",
    "# df = pd.read_csv('data/tweet_id/1319748517397659654.csv')\n",
    "# df = pd.read_csv('data/tweet_id/1324002766386323456.csv')\n",
    "# df = pd.read_csv('data/tweet_id/1329901868315623424.csv')\n",
    "# df = pd.read_csv('data/tweet_id/1332477653685825536.csv')\n",
    "# df = pd.read_csv('data/tweet_id/1332518860944076802.csv')\n",
    "# df = pd.read_csv('data/tweet_id/1332552283553476608.csv')\n",
    "df = pd.read_csv('data/tweet_id/1332713121413214208.csv')\n",
    "# df = df[:9]\n",
    "# 超参数\n",
    "lr = 1e-7\n",
    "epochs = 300\n",
    "batch_size = 1\n",
    "train_rate = 0.1\n",
    "train_len = int(train_rate * len(df))\n",
    "\n",
    "\n",
    "# train_ds = PairWiseDataset(df[:train_len])\n",
    "# trainLoader = DataLoader(train_ds, shuffle=True, batch_size=batch_size)\n",
    "# test_ds = PairWiseDataset(df[train_len:])\n",
    "# testLoader = DataLoader(test_ds, shuffle=True, batch_size=1)\n",
    "\n",
    "train_ds_x = df.drop(labels=['seq', 'o_tid'], axis=1)\n",
    "train_ds_x = torch.from_numpy(train_ds_x.values)\n",
    "train_ds_y = torch.from_numpy(df['seq'].values)\n",
    "\n",
    "tot = train_ds_x.shape[0]\n",
    "\n",
    "# model = MyModel()\n",
    "model = torch.load('./model/model_model.pth')\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.MarginRankingLoss()\n",
    "for epoch in range(epochs):\n",
    "    tot_loss = 0.0\n",
    "    batch_num = 0\n",
    "    for i in range(tot):\n",
    "        for j in range(i+1, tot):\n",
    "            batch_num += 1\n",
    "            optimizer.zero_grad()\n",
    "            pred_y_1 = model(train_ds_x[i])\n",
    "            pred_y_2 = model(train_ds_x[j])\n",
    "            target = 1\n",
    "            if train_ds_y[i] > train_ds_y[j]:\n",
    "                target = -1\n",
    "            loss = criterion(pred_y_1, pred_y_2, torch.tensor([target]))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tot_loss += loss.item()\n",
    "        # print(i)\n",
    "\n",
    "    print(f'epoch = {epoch}  loss = {tot_loss / batch_num}')\n",
    "\n",
    "\n",
    "\n",
    "# for i, (x1, x2, y1, y2) in enumerate(trainLoader):\n",
    "#     print(\"--------------------------------\")\n",
    "#     print(\"x1\")\n",
    "#     print(x1)\n",
    "#     print(\"x2\")\n",
    "#     print(x2)\n",
    "#     print(\"y1\")\n",
    "#     print(y1)\n",
    "#     print(\"y2\")\n",
    "#     print(y2)\n",
    "#     break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "WEIGHT = './model/model_weights.pth'\n",
    "MODEL = './model/model_model.pth'\n",
    "torch.save(model.state_dict(), WEIGHT)\n",
    "torch.save(model, MODEL)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# model = torch.load('./model/model_model.pth')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
